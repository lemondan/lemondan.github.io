<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="utf-8">
  
  <title>Xiaodan Liang</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="Resources  Code: RGB-D Scene Parsing | Pedestrain Detection  Dataset: Human Parsing | Clothes Co-Parsing | Structured Scene Parsing | Focal Liver Lesions Recognition in CEUS  Selected Projects">
<meta property="og:type" content="website">
<meta property="og:title" content="Xiaodan Liang">
<meta property="og:url" content="https://lemondan.github.io/projects/index.html">
<meta property="og:site_name" content="Xiaodan Liang">
<meta property="og:description" content="Resources  Code: RGB-D Scene Parsing | Pedestrain Detection  Dataset: Human Parsing | Clothes Co-Parsing | Structured Scene Parsing | Focal Liver Lesions Recognition in CEUS  Selected Projects">
<meta property="og:locale" content="default">
<meta property="og:image" content="http://www.cs.cmu.edu/afs/cs/user/xiaodan1/www/image/graphlstm.jpg">
<meta property="og:image" content="http://www.cs.cmu.edu/afs/cs/user/xiaodan1/www/image/instance.jpg">
<meta property="og:image" content="http://www.cs.cmu.edu/afs/cs/user/xiaodan1/www/image/babylearning.jpg">
<meta property="og:image" content="http://www.cs.cmu.edu/afs/cs/user/xiaodan1/www/image/cocnn.jpg">
<meta property="og:updated_time" content="2019-12-22T11:56:37.786Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Xiaodan Liang">
<meta name="twitter:description" content="Resources  Code: RGB-D Scene Parsing | Pedestrain Detection  Dataset: Human Parsing | Clothes Co-Parsing | Structured Scene Parsing | Focal Liver Lesions Recognition in CEUS  Selected Projects">
<meta name="twitter:image" content="http://www.cs.cmu.edu/afs/cs/user/xiaodan1/www/image/graphlstm.jpg">
  
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  

  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.6/css/bootstrap.min.css" integrity="sha384-1q8mTJOASx8j1Au+a5WDVnPi2lkFfwwEAa8hDDdjZlpLegxhjVME1fgjWPGmkzs7" crossorigin="anonymous">

  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.5.0/css/font-awesome.min.css" integrity="sha384-XdYbMnZ/QjLh6iI4ogqCTaIjrFk87ip+ekIjefZch0Y+PvJ8CDYtEs1ipDmPorQ+" crossorigin="anonymous">

  <link rel="stylesheet" href="/css/styles.css">
  

</head>
</html>
<body>
  <nav class="navbar navbar-inverse">
  <div class="container">
    <!-- Brand and toggle get grouped for better mobile display -->
    <div class="navbar-header">
      
        <a class="navbar-brand" href="/">Xiaodan Liang</a>
      
    </div>

    <!-- Collect the nav links, forms, and other content for toggling -->
    <div class="collapse navbar-collapse" id="main-menu-navbar">
      <ul class="nav navbar-nav">
        
          <li><a class="" href="/publications/">Publications</a></li>
        
          <li><a class="" href="/tutorials/">Tutorials</a></li>
        
          <li><a class="active" href="/projects/">Projects</a></li>
        
      </ul>

      <!--
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
      -->
    </div><!-- /.navbar-collapse -->
  </div><!-- /.container-fluid -->
</nav>

  <div class="container">
    <div class="blog-header">
  
</div>

    <div class="main">
      <article id="page-undefined" class="article article-type-page" itemscope="" itemprop="blogPost">

  

  <div class="article-inner">

    <div class="article-entry" itemprop="articleBody">
      <p><strong><font color="#4590a3" size="4px">Resources</font></strong></p>
<ul>
<li><strong>Code</strong>: <a href="http://hcp.sysu.edu.cn/rgbd-scene-labeling/" target="_blank" rel="noopener">RGB-D Scene Parsing</a> | <a href="http://hcp.sysu.edu.cn/?p=766" target="_blank" rel="noopener">Pedestrain Detection</a> </li>
<li><strong>Dataset</strong>: <a href="http://hcp.sysu.edu.cn/?p=666" target="_blank" rel="noopener">Human Parsing</a> | <a href="https://github.com/bearpaw/clothing-co-parsing" target="_blank" rel="noopener">Clothes Co-Parsing</a> | <a href="http://hcp.sysu.edu.cn/sysu-scenes/" target="_blank" rel="noopener">Structured Scene Parsing</a> | <a href="http://hcp.sysu.edu.cn/recognizing-focal-liver-lesions-in-ceus-with-dynamically-trained-latent-structured-models/" target="_blank" rel="noopener">Focal Liver Lesions Recognition in CEUS</a></li>
</ul>
<p><strong><font color="#4590a3" size="4px">Selected Projects</font></strong></p>
<ul class="item"><br>    <li class="item"><br>        <img class="item-box" src="http://www.cs.cmu.edu/afs/cs/user/xiaodan1/www/image/graphlstm.jpg" style="float:left; margin-right: 10px; height: 200px; width: 280px"><br>        <span class="item-title">Semantic Object Parsing with Graph LSTM <a class="item" href="//www.cs.cmu.edu/afs/cs/user/xiaodan1/www/image/eccv2016_graphlstm.pdf">[PDF]</a></span><br><br>        <span class="item">We propose a novel Graph LSTM model that extends the traditional LSTMs from sequential and multi-dimensional data to general graph-structured data. Instead of evenly and fixedly dividing an image into pixels or patches as previous LSTMs did, Graph LSTM takes each arbitrary-shaped superpixel as a semantically consistent node of a graph, while the spatial neighborhood relations are naturally used to construct the undirected graph edges.<br><br>        <span class="italic">European Conference on Computer Vision (ECCV), 2016 </span> (<strong>Spotlight</strong>)<br><br>    </span></li><br>    <li><br>        <img class="item-box" src="http://www.cs.cmu.edu/afs/cs/user/xiaodan1/www/image/instance.jpg" style="float:left; margin-right: 10px; height: 200px; width: 280px"><br>        <span class="item-title"> Reversible Recursive Instance-level Object Segmentation <a class="item" href="//users.eecs.northwestern.edu/~xsh835/assets/cvpr2016_recursivesegmentation.pdf">[PDF]</a></span><br><br>        <span class="item">We propose a novel Reversible Recursive Instance-level Object Segmentation (R2-IOS) framework to address the challenging instance-level object segmentation task. R2-IOS consists of a reversible proposal refinement sub-network that predicts bounding box offsets for refining the object proposal locations, and an instance-level segmentation sub-network that generates the foreground mask of the dominant object instance in each proposal.<br><br>        <span class="italic">IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2016 </span> <br><br>    </span></li><br>    <li><br>        <img class="item-box" src="http://www.cs.cmu.edu/afs/cs/user/xiaodan1/www/image/babylearning.jpg" style="float:left; margin-right: 10px; height: 200px; width: 280px"><br>        <span class="item-title"> Towards Computational Baby Learning: A Weakly-supervised Approach for Object Detection <a class="item" href="//ss.sysu.edu.cn/~ll/files/ICCV2015_BabyLearning.pdf">[PDF]</a></span><br><br>        <span class="item">Intuitive observations show that a baby may inherently possess the capability of recognizing a new visual concept (e.g.,  chair,  dog)  by  learning  from  only  very  few  positive instances taught by parent(s) or others,  and this recognition capability can be gradually further improved by exploring and/or interacting with the real instances in the physical  world.   Inspired  by  these  observations,  we  propose  a computational  model  for  slightly-supervised  object  detection.<br><br>        <span class="italic">IEEE International Conference on Computer Vision (ICCV), 2015 </span> <br><br>    </span></li><br>    <li><br>        <img class="item-box" src="http://www.cs.cmu.edu/afs/cs/user/xiaodan1/www/image/cocnn.jpg" style="float:left; margin-right: 10px; height: 200px; width: 280px"><br>        <span class="item-title"> Human Parsing with Contextualized Convolutional Neural Network <a class="item" href="//users.eecs.northwestern.edu/~xsh835/assets/iccv2015_cocnn_parsing.pdf">[PDF]</a><a class="item" href="//hcp.sysu.edu.cn/?p=666">[Page with Data]]</a></span><br><br>        <span class="item">We address the human parsing task with a novel Contextualized Convolutional Neural Network (Co-CNN) architecture, which well integrates the cross-layer context, global image-level context, within-super-pixel context and cross-super-pixel neighborhood context into a unified network.<br><br>        <span class="italic">IEEE International Conference on Computer Vision (ICCV), 2015 </span> (<strong>Oral</strong>)<br><br><br><br><br>    </span></li><br></ul>

    </div>

    
      
    

  </div>
</article>


    </div>
  </div>
  <footer class="blog-footer">
  <div class="container">
    <div id="footer-info" class="inner">
      &copy; 2019 Xiaodan Liang<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>

  

<script src="https://ajax.googleapis.com/ajax/libs/jquery/2.1.4/jquery.min.js" integrity="sha384-8gBf6Y4YYq7Jx97PIqmTwLPin4hxIzQw5aDmUg/DDhul9fFpbbLcLh3nTIIDJKhx" crossorigin="anonymous"></script>

<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.6/js/bootstrap.min.js" integrity="sha384-0mSbJDEHialfmuBBQP6A4Qrprq5OVfW37PRR3j5ELqxss1yVqOtnepnHVP9aJ7xS" crossorigin="anonymous"></script>



<script src="/js/script.js"></script>

</body>
</html>
